## 背景介绍

当前就职的这家公司中的Dubbo服务使用的`zookeeper`作为注册中心, 之前使用的虚拟机, 业务服务和zookeeper部署到了相同的服务器上, 后来逐渐把服务迁移到了k8s容器中, 剩下的机器就空余出来了很多, 就需要调整zookeeper的节点, 也就是需要新增节点和删除节点, 并且让业务连接zookeeper使用域名, 而不是直接使用IP地址, 所以趁这个机会总结一下zookeeper的安装/添加节点/删除节点的教程


## 安装单机版本

一般来说开发环境/测试环境安装一个单机版本的zookeeper就能够满足需求了; 安装之前请自行安装Java

#### 下载zookeeper压缩包

一般下载最新stable版本, 下载地址如下:

[https://zookeeper.apache.org/releases.html](https://zookeeper.apache.org/releases.html#download)

#### 配置文件

* 复制conf目录下配置文件

```
cp zoo_sample.cfg zoo.cfg
```

比较重要的配置如下:

```
# zookeeper的数据存放位置, 快照/事务日志等, 最好自己指定, 别放到/tmp目录
dataDir=/data/zookeeper
# 客户端连接的端口
clientPort=2181

# 3.5.0以后的版本, zookeeper会自动启动一个内置的HTTP服务, 默认的端口为8080, 如果跟以后的服务冲突的话可以
# 修改如下的端口配置
admin.serverPort=8988
```


* 日志目录

经测试, 直接修改日志配置文件`log4j.properties`或者`logback.xml`不怎么生效, 还是需要修改bin目录下的`zkEnv.sh`文件中的`ZOO_LOG_DIR`变量;

到此, 关键的配置都已经搞完了, 下一步直接启动就行

#### 启停服务

进入`bin`目录下执行如下命令:

```
./zkServer.sh start ../conf/zoo.cfg
```

> 重启停止等直接替换start就行, 注意后面跟着的配置文件, 如果同一个服务器上启动了多个实例就必须用到了


到此单机版本就安装完成了

## 搭建集群

#### zookeeper集群的一些知识点

* zookeeper集群因为会选举leader节点, 所以最好配置奇数个节点的集群
* zookeeper集群只有半数以上的节点存活的情况下才可以提供服务, 所以有3个节点的集群, 只允许挂掉一台, 5台的集群只允许挂掉2台;
* 集群可以有偶数个节点, 但是因为集群必须为半数以上存活才可以提供服务, 所以4个节点的集群也是只允许有一个节点挂掉, 不然挂2个就是半数了, 不满足半数以上存活, 也就是4个节点的效果跟3个节点的效果一样
* 客户端了连接集群最好通过域名, 这样节点出问题, 故障转移的时候, 业务就无需修改配置文件了


#### 写hosts

一般集群都是3个节点或者5个节点, 首先配置好hosts, 下面会用到, 实例如下:

```
/etc/hosts

192.168.1.1 zk01
192.168.1.2 zk02
192.168.1.3 zk03
```

将上面的文件复制到每个节点的`/etc/hosts`文件中

#### zookeeper配置文件

关键的配置文件:

```
# zookeeper的数据存放位置, 快照/事务日志等, 最好自己指定, 别放到/tmp目录
dataDir=/data/zookeeper
# 客户端连接的端口, 注意这里的端口跟下面的集群配置那块不一样
clientPort=2181
# server后面的数字, 是有几个节点就写几个, 2888是集群通信地址, 3888用于leader节点选举通信
server.1=zk01:2888:3888
server.2=zk02:2888:3888
server.3=zk03:2888:3888
```

#### 配置myid

ZooKeeper 集群中每个节点都必须被分配一个唯一的 ID。每个节点的 ID 必须配置在`myid`文件中，并存储在`dataDir`文件夹中，如`/data/zookeeper/`。myid 文件应只包含一个行，其中的 ID 写为文本。ID 可以是 1 到 255 的任何整数。您必须在每个集群节点上`手动创建此文件`。使用这个文件，每个 ZooKeeper 实例将使用配置文件 server. 行中的相应配置来配置其监听程序。它还将使用所有其他 server. 行识别其他群集成员。

```
echo 1 > myid
```

#### 启动服务

依次启动每个节点的服务, 然后检查每个节点的状态:

```
# ./zkServer.sh status ../conf/zoo.cfg
ZooKeeper JMX enabled by default
Using config: ../conf/zoo.cfg
Mode: leader

# ./zkServer.sh status ../conf/zoo.cfg
ZooKeeper JMX enabled by default
Using config: ../conf/zoo.cfg
Mode: follower
```

## 集群增减节点

* 配置每个节点的hosts, 将新增的节点的主机加进去
* 每个节点的zookeeper配置文件新增一行`server.X=zk0X:2888:3888`
* 在新的节点上启动服务并查看状态
* 依次重启其他节点的服务并查看装台
* 注意在业务低峰期操作
* 删除节点方式类似
* 可以通过依次重启节点来验证故障转移

## 常用命令总结

#### 使用客户端连接

```
./zkCli.sh -server 192.168.1.1:2181
```

#### 查看路径

```
[zk: localhost:2181(CONNECTED) 3] ls /
[dubbo, zookeeper]
```

#### 获取节点内容和状态

```
[zk: localhost:2181(CONNECTED) 4] get /dubbo/config
10.46.176.105

cZxid = 0x50000000f
ctime = Wed Jan 06 03:17:08 CST 2021
mZxid = 0x50000000f
mtime = Wed Jan 06 03:17:08 CST 2021
pZxid = 0x80016bff2
cversion = 7
dataVersion = 0
aclVersion = 0
ephemeralOwner = 0x0
dataLength = 13
numChildren = 7
```

#### 创建节点和数据

可以通过在一个节点上创建, 然后去集群的其它节点上查看数据来验证集群的同步状态

```
create /test abc
```

#### 查看某一个节点的状态

```
echo stat | nc 127.0.0.1 2181

Zookeeper version: 3.4.8--1, built on 02/06/2016 03:18 GMT
Clients:
 /172.17.108.83:56558[1](queued=0,recved=678,sent=678)
 /172.17.135.173:6982[1](queued=0,recved=1014,sent=1014)
 /172.17.108.83:58602[1](queued=0,recved=448,sent=448)
 /172.17.135.156:60797[1](queued=0,recved=1554,sent=1554)
 /172.17.108.83:56964[1](queued=0,recved=454,sent=454)
 /172.17.135.169:39084[0](queued=0,recved=1,sent=0)
 /172.17.108.83:54472[1](queued=0,recved=4363,sent=4365)
 /172.17.108.83:43520[1](queued=0,recved=812,sent=812)
 /172.17.108.83:42222[1](queued=0,recved=483,sent=483)

Latency min/avg/max: 0/0/17
Received: 369460
Sent: 369475
Connections: 9
Outstanding: 0
Zxid: 0x900004fb2
Mode: follower
Node count: 8679
```


## 参考文档

* [zookeeper Admin Guide](https://zookeeper.apache.org/doc/)
* [https://pengdafu.github.io/zookeeper/docs/zk_cluster.html](https://pengdafu.github.io/zookeeper/docs/zk_cluster.html)