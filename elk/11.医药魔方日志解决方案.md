#### 背景介绍



大部分中小互联网公司日志解决方采用的都是ELK, 简单省事儿, 不用二次开发, 这里把在医药魔方的ELK方案的要点记录一下, 核心的组件没有变化, 变化的是容器化等部署方式.



#### 日志生成



中小企业使用Spring全家桶的比较多, 以前的日志打印就是普通的一行一行的文本, 经过filebeat采集到ES后都存储在`message`一个字段里面, 不太好利用ES强大的检索功能.



ES公司为了解决这个问题, 搞了一套打日志的标准, 简称`ECS`, 同时提供了各个语言框架的SDK, 引入这个SDK以后, 日志打印的就是一行一行的json了



同时, 我们让每一个服务打印日志的时候加上了服务的appCode以及环境, 示例如下:



```
{"@timestamp":"2024-05-24T02:10:28.677Z","log.level": "INFO","message":"日志详细内容","service.name":"sre-demo-provider","service.environment":"PROD","service.address":"192.168.1.1", ...}
```

这样在采集的时候就是一个json的格式, 可以直接放到ES里面了.



当然同事也搞了一个脚手架, 就是把每个方法的入参和出参打印了出来, 统一了日志基础配置等等.当然这个跟上面的json的没有直接的关系.



到这一步其实就是服务打印了json文件, 为了方便采集, k8s日志采用的是hostpath, 这个不在这里说了.



#### 日志采集



filebeat采用daemonset的方式部署到了k8s集群中, filebeat.yaml示例配置如下:



```yaml
filebeat.yml
filebeat.inputs:
- type: filestream
  id: pharmcube-log-id
  paths:
    - /data/logs/*/*.json
  parsers:
    - multiline:
       type: pattern
       pattern: '^{'
       negate: true
       match: after
# ======================= Elasticsearch template setting =======================
setup.template.name: "backend-service-log-index-template"
setup.template.pattern: "filebeat-*"
setup.template.settings:
  index.number_of_shards: 3
  index.number_of_replicas: 0  

fields:
  containerized: true

output.elasticsearch:
  hosts: ["ES地址"]
  username: "username"
  password: "password"
  worker: 3  
  indices:
    - index: "appCode"
      when.equals:
        service.name: "appCode"
    - index: "default"

processors:
  # 查看宿主机的IP暂时使用prometheus的查询, 打印出来会采集PODIP, 而且无用信息太多, 数据查询慢
  #- add_host_metadata: ~
  - decode_json_fields:
      fields: message
      target: ""
      overwrite_keys: true
      expand_keys: true
  - script:
      when:
        has_fields: ['error.stack_trace']
      lang: javascript
      timeout: 10s
      source: >
        function process(event) {
            event.Put("error.stack_trace", event.Get("error.stack_trace").join("\n"));
        }
```



这里有几个比较重要的配置做一个说明:



* setup.template.name



这个配置指明了filebeat采集日志往ES写入的时候使用ES的哪个索引模板, 索引模板配置了索引的一些基本配置, 比如几个分片/几个副本/字段类型等等



* setup.template.pattern

这个是索引模板要适用到哪些索引上, 是一个通配符, 这里只能写字符串, 如果ES上没有的话就会创建, 有的话默认不会修改, 当然也有选项可以覆盖, 一般也不覆盖. 索引模板可以定义很多个, 不同模板可以写相同的索引通配符, 但是优先级不能相同, 创建索引的时候可以显性指定索引模板, 如果不指定, ES会根据匹配到该索引的索引模板中优先级最高的那个. 比如你的服务都是`web-*`, 那就可以直接在这里直接配制, 如果采集的日志的索引不止`web-*`, 那么可以在这里这个, 然后去kibana的索引模板管理那边配置其余的, 如下图:

<img width="1508" alt="image" src="https://github.com/wufeiqun/blog/assets/7486508/b7484773-cf8e-40a5-888d-b0de2451b556">



* indices

这里是根据日志中服务的appCode创建不同的ES datastream, 不用加日期, 每个应用一个datastream, appCode是运维平台中生成的, 会保证全局唯一.  没有配置appCode的会走到`default`的那个datastream, 这里使用的when.equals, 经过测试, 使用when.has_fields, 然后index那块结合变量的方式, 想着是配置一条规则, 而不是每个服务手工加一个when, 但是失败了, 不知道为什么, 后面再详细研究吧.



#### 日志查看



日志经过filebeat采集后会存储到ES中, 每个appCode一个datastream, 使用kibana的dataview查看日志, dataview配置index pattern的时候可以直接写死固定的appCode命名的datastream, 这样就可以实现每个appCode一个dataview, 每个dataview绑定一个datastream.



所有经过filebeat采集的日志的datastream都会使用同一个索引模板, 同时经过filebeat采集的日志默认都会使用同一个生命周期, 名字为`filebeat`, 还需要去配置一下生命周期, 加上一个自动删除的策略.

<img width="2494" alt="image" src="https://github.com/wufeiqun/blog/assets/7486508/80b7d30a-376d-48a6-b4a6-9d9aab55840d">





#### 参考文档



* [Introduction | ECS Logging Reference | Elastic](https://www.elastic.co/guide/en/ecs-logging/overview/current/intro.html)


